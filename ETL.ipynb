{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57d571f-d0b1-41c3-89df-e2d6e3ae85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Set up basic logging\n",
    "logging.basicConfig(\n",
    "    filename='etl_log.txt',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e5a2d4c-4ea0-4695-9b30-8e9065c10942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded:\n",
      "   EMPLOYEE_ID FIRST_NAME  LAST_NAME     EMAIL  PHONE_NUMBER  HIRE_DATE  \\\n",
      "0          198     Donald   OConnell  DOCONNEL  650.507.9833  21-Jun-07   \n",
      "1          199    Douglas      Grant    DGRANT  650.507.9844  13-Jan-08   \n",
      "2          200   Jennifer     Whalen   JWHALEN  515.123.4444  17-Sep-03   \n",
      "3          201    Michael  Hartstein  MHARTSTE  515.123.5555  17-Feb-04   \n",
      "4          202        Pat        Fay      PFAY  603.123.6666  17-Aug-05   \n",
      "\n",
      "     JOB_ID  SALARY  \n",
      "0  SH_CLERK    2600  \n",
      "1  SH_CLERK    2600  \n",
      "2   AD_ASST    4400  \n",
      "3    MK_MAN   13000  \n",
      "4    MK_REP    6000  \n",
      "Column names: ['EMPLOYEE_ID', 'FIRST_NAME', 'LAST_NAME', 'EMAIL', 'PHONE_NUMBER', 'HIRE_DATE', 'JOB_ID', 'SALARY']\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'employees1.csv'  # Make sure this file is in your working directory\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "print(\"Raw data loaded:\")\n",
    "print(df.head())\n",
    "print(\"Column names:\", df.columns.tolist())\n",
    "\n",
    "logging.info(\"CSV loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b978e0-4101-44d3-9079-7c22288e79dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned column names: ['employee_id', 'first_name', 'last_name', 'email', 'phone_number', 'hire_date', 'job_id', 'salary']\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "df.fillna({\n",
    "    'EMAIL': 'not_provided@example.com',\n",
    "    'PHONE_NUMBER': '0000000000',\n",
    "    'HIRE_DATE': '01-Jan-00',\n",
    "    'SALARY': 0\n",
    "}, inplace=True)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
    "print(\"Cleaned column names:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45a4e07b-60c6-4526-ab73-9ecf36fb6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'hire_date' to datetime\n",
    "df['hire_date'] = pd.to_datetime(df['hire_date'], format='%d-%b-%y', errors='coerce')\n",
    "\n",
    "# Replace invalid dates with default\n",
    "df['hire_date'] = df['hire_date'].fillna(pd.to_datetime('2000-01-01'))\n",
    "\n",
    "# Convert 'salary' to numeric\n",
    "df['salary'] = pd.to_numeric(df['salary'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "logging.info(\"Data cleaning completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "259f18f4-b926-41cc-9d0e-f44e737e07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection without database\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Aditiyak@3821\"\n",
    ")\n",
    "\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "# Create the database if it doesn't exist\n",
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS employee\")\n",
    "\n",
    "# âœ… Reconnect with the selected database\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Aditiyak@3821\",\n",
    "    database=\"employee\"\n",
    ")\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS salary_2 (\n",
    "        empid INT PRIMARY KEY,\n",
    "        firstname VARCHAR(50),\n",
    "        lastname VARCHAR(50),\n",
    "        email VARCHAR(100),\n",
    "        phone VARCHAR(20),\n",
    "        hire_date DATE,\n",
    "        job_id VARCHAR(20),\n",
    "        salary INT\n",
    "    )\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "381cc496-7bfb-412b-8d2f-30dca51853fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    sql = \"\"\"\n",
    "        INSERT INTO salary_2 (\n",
    "            empid, firstname, lastname, email, phone, hire_date, job_id, salary\n",
    "        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ON DUPLICATE KEY UPDATE\n",
    "            firstname=VALUES(firstname),\n",
    "            lastname=VALUES(lastname),\n",
    "            email=VALUES(email),\n",
    "            phone=VALUES(phone),\n",
    "            hire_date=VALUES(hire_date),\n",
    "            job_id=VALUES(job_id),\n",
    "            salary=VALUES(salary)\n",
    "    \"\"\"\n",
    "\n",
    "    values = (\n",
    "        int(row['employee_id']),\n",
    "        row['first_name'],\n",
    "        row['last_name'],\n",
    "        row['email'],\n",
    "        row['phone_number'],\n",
    "        row['hire_date'].date(),\n",
    "        row['job_id'],\n",
    "        int(row['salary'])\n",
    "    )\n",
    "\n",
    "    cursor.execute(sql, values)\n",
    "\n",
    "mydb.commit()\n",
    "cursor.close()\n",
    "mydb.close()\n",
    "\n",
    "logging.info(\"ETL process completed successfully.\")\n",
    "print(\"ETL process completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38da2905-e72c-47c0-8b66-9aba5251573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/aditya/JS\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb1965ce-8391-4675-a0c5-0d728f473b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'Pipeline' matched no files\n",
      "[NbConvertApp] WARNING | pattern 'CSV' matched no files\n",
      "[NbConvertApp] WARNING | pattern 'to' matched no files\n",
      "[NbConvertApp] WARNING | pattern 'MySQL' matched no files\n",
      "[NbConvertApp] WARNING | pattern 'Data' matched no files\n",
      "[NbConvertApp] WARNING | pattern 'Ingestion.ipynb' matched no files\n",
      "[NbConvertApp] Converting notebook ETL.ipynb to script\n",
      "[NbConvertApp] Writing 2934 bytes to ETL.py\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('jupyter nbconvert --to script ETL Pipeline CSV to MySQL Data Ingestion.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacffa7c-9c0b-45f3-b501-4f55d0ce3bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
